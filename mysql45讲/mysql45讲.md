#      mysql45讲



## 基础篇

### 基础架构

**mysql基本架构示意图**：

![img](mysql45%E8%AE%B2.assets/0d2070e8f84c4801adbfa03bda1f98d9.png)

**连接器**

```mys
mysql -h$ip -P$port -u$user -p
```

- 若不指定ip与端口，则默认为localhost的默认端口(3306)
- tcp握手后便进行身份验证，校验用户与密码
- 用户密码认证通过后，会从权限表中查询该连接对应的权限，并且，此次连接后，即使管理员修改了该用户的权限，此次连接的权限也不变，建立新的连接后才会使用新的权限设置

**长连接/短链接**

长连接为连接成功，客户端持续请求都使用这一个连接

短链接为执行很少几次的查询断开连接，下次查询重新建立连接

建议使用长连接，但是长链接过多时会导致资源占用过多而不被释放，最后导致OOM重启

解决方法：

- 定期断开长连接
- mysql_reset_connection重新初始化连接资源(mysql 5.7及以上)

**查询缓存**

mysql将执行过的语句和查询的结果以key-value的形式存储

- 查询后若缓存命中则直接返回结果
- 每次数据更新导致缓存被清空，因此命中率较低
- 适用于静态查询表
- mysql8.0缓存被删除

**分析器**

词法分析->语法分析：

- 词法分析识别出其中的字符串是什么
- 语法分析检验语法

**优化器**

- 多个索引的情况下选择索引的使用
- join的先后顺序

经过优化器之后，便可以确定执行方案，交给执行器进行执行

**执行器**

首先判断权限，是否有查询该表的权限

之后根据表的引擎定义，使用这个引擎对应的接口

### 日志系统

与查询不同的是，更新语句还涉及日志模块，分别为redo log 和 bin log

**redo log**

MYSQL中的Write-Ahead Logging(WAL)技术：先写日志，再写磁盘

更新是InnoDB先将记录写道rodo log中，再空闲时再从redo log中写入到硬盘之中

与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写

![img](mysql45%E8%AE%B2.assets/16a7950217b3f0f4ed02db5db59562a7.png)

write pos处写入，check point处擦除，当write pos追上check point时，即为已经写满，需要将一部分写入磁盘，推荐check point

redo log 分为两部分，一部分为存储在内存中的redo buffer ，另一部分真正写入磁盘之中，如果发生断电，则redo buffer中的丢失，事务回滚

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。

**bin log**

最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。

binlog与redolog的不同：

- redolog InnoDB特有，binlog为mysql server层实现的 任何引擎都可以使用
- redolog为物理日志，记录在某个数据页上做了什么修改，binlog为逻辑日志，记录语句的原始逻辑 statement格式记录sql语句，row格式记录行的内容
- redo log循环写，空间大小固定会用完，binlog可切换新的文件进行追加
- 备份时即为备份 binlog 用于归档

**执行过程：两阶段提交**

```mysql
mysql> update T set c=c+1 where ID=2;
```

![img](mysql45%E8%AE%B2.assets/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

通过两阶段提交，全部写入成功后再提交事务，保证两份日志的逻辑一致

若不使用两阶段提交：

- 先redo log后bin log：crash后redo log进行数据恢复，值被修改，但是备份中的值未被修改
- 先bin log后 redo log：crash后成功备份但是当前值为改变

 ### 事务隔离

事务：ACID 原子性、一致性、隔离性、持久性

隔离级别：

- 读未提交：事务未提交时别的事务就可以看到
- 读提交：该事务提交后所作的变更才能被别的事务看到
- 可重复读：该事务执行过程中看到的数据一致（同一个视图内的数据一致）在事务启动后，对于其他事务进行的改动不承认，只会去找在事务启动时那一时刻的数据版本，但是，对于本事务的改动，依旧会承认(对于本事务进行的更新，存在当前读的情况，详情见后)
- 串行化：对同一条记录进行上锁

隔离性自上至下依次增强，并行性能依次减弱

![img](mysql45%E8%AE%B2.assets/7dea45932a6b722eb069d2264d0066f8-16546557330432.png)

查询结果：

- 读未提交：V1:2 V2: 2 V3 2
- 读提交：V1:1 V2:2 V3:2
- 可重复读：V1:1 V2:1 V3:2(事务A执行过程中读取的数据相同)
- 串行化：V1:1 V2: 1 V3: 2(B修改时会被锁到A事务提交完)

**视图**

实现上数据库会创建一个视图，查询结果以视图为准，

- 可重复读的隔离级别下，视图在事务启动时创建(事务在第一个select时启动，注意区分创建和启动的概念)，整个事务时期都使用这个视图。

- 读提交下，为在SQL语句开始执行时创建，每一条语句执行前都会重新计算出一个新的视图
- 读未提交下，在直接返回记录上的最新值，没有视图概念
- 串行化直接通过加锁的方式

**事务隔离的实现**

MYSQL每次更新时同时记录一条回滚操作

![img](mysql45%E8%AE%B2.assets/d9c313809e5ac148fc39feff532f0fee.png)

一个值顺序从 1被改成2、3、4，回滚段则为记录逆向操作

> 在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

**数据库中并不会记录1、2、3这几个值，只会保存回滚日志undo log，想要得到1，只能通过undo log进行一步步的计算得来**

回滚日志的删除：

​	当系统内没有比当前回滚日志更早的视图时，即为没有事务会再用到该回滚日志，就会删除该回滚日志

​	如当事务A执行完，视图消失后，对应的回滚日志将2改成1也一并被删除

尽量避免使用长事务：

​	该事务被提交前，所有的回滚日志都会被保存，占用大量空间，拖垮数据库

**事务启动方式**

建议使用`set autocommit = 1`再通过显示语句`begin`或`start transaction`进行启动，避免`set autocommit = 0`长事务

### 索引

作用：提高查询效率

本质：B+树，每多添加一个索引就多一棵B+树（InnoDB中）

**常见模型**

- 哈希表：适合等值查询，由于其无序性，区间查询则需要整个进行遍历

- 有序数组：等值查询和范围查询都性能优秀，但是插入时移动数组性能损耗大，只适用于静态存储引擎
- 二叉搜索树：查询的时间复杂度为O(log(N))，为了保持树为平衡二叉树，更新复杂度也为O(log(N))
  - 存在的问题：树过高，在磁盘中一次读取一个子节点，内存与硬盘的交互过程中开销大
  - 解决方式：查询过程中尽可能少的访问数据块，使用N叉树：一次访问获取多个数据或多个后续节点

**InnoDB的索引模型**

B+树，一个索引对应一个B+树

​	B+树中只有叶子节点存放数据，并且不同叶子节点之间使用链表进行连	接，其他只存放索引

[MySQL索引底层：B+树详解 - 掘金 (juejin.cn)](https://juejin.cn/post/6929833495082565646)

设置主键为id，索引为k: 

```mysql
mysql> create table T(
id int primary key, 
k int not null, 
name varchar(16),
index (k))engine=InnoDB;
```

对应的索引树如下

- 主键索引中存放整行数据

- 非主键索引(二级索引)存放主键的值：查询时需要进行回表（先查询到主键，在通过主键索引进行查询）

![img](mysql45%E8%AE%B2.assets/dcda101051f28502bd5c4402b292e38d.png)

**索引维护**

- 追加插入：直接在叶子节点后进行追加
- 中间插入：涉及到数组的移动
- 数据页满：叶子的分裂(具体过程看B+树算法)，空间利用率降低50%

自增主键在插入时直接追加，不涉及数组的移动，并且本身占空间小(int 4字节,bigint8字节), 在性能和存储空间上考虑，自增主键较为合理



1. **覆盖索引**：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据 

2. **最左前缀**：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符 (通过like进行模糊匹配时) 当存在(a,b)这个索引时，一般不需要再建立单独a的索引         
3. **联合索引**：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。 
4. **索引下推**：like 'hello%’and age >10 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度



### 全局锁和表锁

**全局锁**

MYSQL 使用 Flush tables with read lock(FTWRL) 让整个库处于只读的状态，通常用于做全库逻辑备份

> 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。

不建议使用`set global readonly = true`的方式令全库只读：

**表级锁**：表锁/元数据锁

**表锁**

- 语法`lock tables ... read/write`
-  可以用unlock tables主动断开，也可在客户端断开时主动释放
- 不仅会限制别的进程的读写，同时本进程的接下来的操作也受限定

> 举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。

**元数据锁**

- 不显式使用，访问表时会自动加上去

- 防止DDL和DML并发的冲突

  - 对一个表进行CRUD时，加读锁
  - 对表结构进行改变时，加写锁

- 事务提交时才会释放

- 分为读锁、写锁   读锁之间不互斥，读锁与写锁，写锁与写锁之间互斥

  故可以有多个线程对同一个表进行CRUD，但是在对表结构进行改变时，不允许别的线程对表结构进行改变以及CRUD

安全的插入字段：

- 解决长事务，防止一直占用MDL锁
- 在alter table语句中设置等待时间，过期超时，防止在请求量大的时候阻塞后面的业务语句

### 行锁

在引擎层由各个引擎负责实现，如MyISAM即不支持行锁，被InnoDB取代

两阶段锁协议：行锁在需要时加上，在事务提交时才释放，故在整个事务当中，应当把最可能引起冲突的锁尽可能的往后放，确保其尽快释放，占用时间较短，影响较小

**死锁和死锁检测**

例：![img](mysql45%E8%AE%B2.assets/4d0eeec7b136371b79248a0aed005a52.jpg)

其中事务A在等待事务B释放掉id=2的行锁，事务B在等待事务A释放掉id=1的行锁，故产生了死锁

应对策略：

- 设置超时时间innodb_lock_wait_timeout，默认时间为50s，手动设置时：
  - 过短：误伤一般的锁
  - 过长：影响了等待时间过长无法接受，如默认的50s在生产环境中过于长
- 死锁检测：innode_deadlock_detece设置为on，默认情况死锁检测即为开启状态,通常也采用这种方式处理死锁
  - 问题：检测本身消耗过大：每次新来的被堵住的线程都要检测会不会因为自己而产生了死锁，复杂度为O(n)
  - 优化：
    - 当确定业务一定不会出现死锁时，手动关闭
    - 控制并发度，令新来的线程不需要进行大量检测排查
    - 将一行改成逻辑上的多行来减少冲突的情况（每行分别计算再进行汇总）

### 视图、锁与多版本数据

事务的启动时机：

- 使用begin/start transaction时，在执行第一个操作innoDB的表时，事务才真正启动
- 使用start tracnsaction with consistent snapshot时，执行命令时创建事务
- 像update此类语句，本身就是一个事务，在执行时创建，语句完成后自动提交、

**视图**：

MYSQL中有两个视图的概念

- 一个时view，用查询结果定义的一个虚拟表，查询他的方法与查询表一致
- 另一个时InnoDB在实现MVCC时使用的一致性视图(consistent read view)，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。

**多版本数据**

每行数据存在多个版本，每个事务在创建时，会获取一个自增的transaction id，用于表明事务的创建时间而在对行内数据进行更新时，会将该transaction id赋值给这个数据版本的事务id，记为row trx_id

数据表中的一行记录，有多个版本，每个版本都用自己的row trx_id，并且可以通过回滚日志计算出上一个版本

![img](mysql45%E8%AE%B2.assets/68d08d277a6f7926a41cc5541d3dfced-16547818091355.png)

> 在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。该视图数组把所有的row trx_id分为了一下几种状态
>
> 1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
> 2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
> 3. 如果落在黄色部分，那就包括两种情况
>    1. a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
>    2. b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

![img](mysql45%E8%AE%B2.assets/882114aaf55861832b4270d44507695e.png)

说明：

1. 在活跃数组中数值最小的row trx_id称为低水位，最大的称为高水位，对于低水位高水位这种说法，只是其一个限定作用，用于确定已经完成的事务和还未开始的事务，而在低水位和高水位这个范围之内的row trx_id，只有真正存在于活跃数组中的才是未提交的事务
2. 对于已经提交的事务，自然能够获取到他的值，同样未开始的事务无法获取，如果当前的版本的row trx_id的只位于红色区域，则需要通过undo log寻找到一个小于高水位并且不存在于活跃数组中的row trx_id，此时才为能够获取到的真正的值
3. 对于在未提交事务中的修改，只有当前线程进行了写操作后（在未提交事务的版本后进行追加，否则未提交事务的版本就会丢失），再次进行读取才能获取到基于未提交事务的值（获取的为当前线程的数据版本），即更新数据时都先读后写，读当前最新版本值，这种特性称之为**当前读** 

> 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
>
> 1. 版本未提交，不可见；
> 2. 版本已提交，但是是在视图创建后提交的，不可见；
> 3. 版本已提交，而且是在视图创建前提交的，可见。

**两阶段锁协议**

![img](mysql45%E8%AE%B2.assets/cda2a0d7decb61e59dddc83ac51efb6e.png)

事务B的更新数据(当前读)操作在C'之前受到阻塞，需要等待事务C的提交释放掉占用的行锁

> 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

**共享锁/排他锁**

加上共享锁和排他锁之后，单独的select也可以变成当前读的状态，从而获取到最新的数据

（有待于深入学习）

## 实践篇

### 普通索引与唯一索引

在查询过程当中，唯一索引遇到条件满足时则立即停止搜索，而普通索引需要寻找到第一个不满足条件的数据，在查询性能上几乎没有差距

**change buffer**

作用：无change buffer 时，要进行数据的修改需要将对应的数据页读到内存当中，修改后再重新写会内存，加入change buffer后避免了这个过程，减少了磁盘的随机访问，提高执行速度

在更新数据页时，如果该数据页位于内存当中，则直接进行更新，如果该数据页不存在与内存中，则先写入change buffer，等待下一次查询将数据页调入到内存当中时，再将操作应用到数据页中，这个过程称为merge

触发merge：

- 访问数据页将数据页调入到内存当中
- 系统后台线程定期merge
- 数据库正常关闭(shutdown)

merge的具体流程：

1. 将数据页从磁盘中读入到内存当中
2. 从change buffer中找到这个数据页对应的记录，应用得到新的数据页
3. 将数据变更和change buffer变更(删除记录)的过程写入到redo log当中
4. 修改数据后的脏页写会到内存当中(另外一个故事)

作用范围：只有在普通索引(二级索引)时才能使用(唯一索引在插入时需要重复性判断，必须将数据页调入到内存当中)

当要更新的记录不存在与内存当中：

- 唯一索引：将数据页调入到内存中，判断是否存在冲突，进行插入，结束
- 普通索引：将更新记录写入到change buffer中，结束

使用场景：写多读少的业务，便于多次写入change buffer后再进行一次merge，与磁盘访问次数少

存储位置：change buffer是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上，在磁盘上占据了系统表空间ibdata

而根据基础篇的第八章所述，update语句存在一个先读后写的过程(当前读)，而update语句需要根据条件更新，具体执行流程如下：

![image-20220610002347123](mysql45%E8%AE%B2.assets/image-20220610002347123.png)

**change buffer/redo log**

- 对于一条更新数据，数据页存在于内存当中直接写入，若不在则写入change buffer

- 而redo log 对于上述两种动作进行记录，再根据这些记录，对磁盘进行更新，即redolog有两种，一种记录普通数据页的改动，一种记录changebuffer的改动

- 真正对磁盘数据页的修改是通过将内存里脏页的数据刷回磁盘来完成的，而不是根据redolog 真正刷新磁盘的工作为innodb中的存储引擎中的线程去做

- change buffer 和redo log 二者的作用目标不同，关注的为两个事情
  - redo log作为一个日志系统，最大的作用为再数据库宕机后的恢复工作

### 优化器索引选择

**优化器的逻辑**

索引的选择为优化器的工作，在绝大多数情况下，优化器都能够正确选择索引

判断标准：扫描的行数，使用临时表，是否排序，同时还有回表所带来的代价

扫描行数：通过基数进行估算

**基数**

- 概念：一个索引上不同的值的个数
- 基数越大，索引的区分度越好
- 计算方式：抽样统计，选取N个数据页，统计页面上的不同值，最后平均，当变更的行数超过了1/M后，会重新进行一次统计
  - 统计方式：通过设置参数 innodb_stats_persistent 的值来选择
    - 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
    - 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

对于以下语句：

```mysql
explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
```

- 扫描a索引需要1000行然后再进行回表

- 扫描b索引需要50000行然后再进行回表

然而最后优化器依然选择了b索引

![image-20220610172752905](mysql45%E8%AE%B2.assets/image-20220610172752905.png)

解决方案：

- force index强制选用a索引
- 优化器之所以选择b索引是因为b索引本身有序，如果使用b则可以避免排序的过程，因此，可以修改sql语句去引导优化器：把“order by b limit 1” 改成 “order by b,a limit 1，逻辑上一致

### 字符串字段索引

由于MYSQL支持前缀索引，故可以选择字符串的一部分来创建索引

- 优点：索引占用的空间更小
- 缺点：
  - 增加匹配次数（前缀部分相同，需要到主键索引上获取完整信息，多次比较）
  - 无法使用索引覆盖

使用前缀索引时应关注区分度，确定一个可以接受的损失比例，适当截取

**其他处理方式**

- 如身份证，学号等前几位高度重合的字段，可以选择使用倒叙存储，则查询时：

  ```mysql
  mysql> select field_list from t where id_card = reverse('input_id_card_string');
  ```

- hash字段：在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。此时只需要四个字节

- 数字型

### 脏页回写

当数据页在内存中经过修改，和硬盘中数据不一样时，称为脏页，需要将脏页会写回硬盘当中，这个过程称为刷脏页(flush)

引发刷脏页的时机：

- redo log写满，需要推进checkpoint，将写在redo log中的操作应用到硬盘之上
- 系统内存不足，进行淘汰页时，如果淘汰的为脏页，则进行flush，但是该过程中不会删除redo log中的记录，redo log在向硬盘中写入时，如果一个数据页被刷过了，则直接跳过
  - 保证了数据页只有两种情况，如果存在于内存之中，那么内存之中的即为正确数据，如果不存在以内存当中，从硬盘中读取的数据页也为正确数据，均可以直接返回，无需再重新应用redo log中记录的操作
  - 如果不是在淘汰脏页时就进行flush，而是选择直接覆盖的话，那么还需要将redo log中记录的操作重新应用于内存中的数据页才能保证数据的正确性，多此一举，不如淘汰时直接进行flush
- MYSQL认为系统空闲时
- MYSQL关闭时

明显影响性能：

- redo log被写满时，整个系统的更新被阻塞
- 一次查询涉及要淘汰的脏页数量过多，查询时间变慢

**刷脏页控制策略**

通过设置innodb_io_capacity的值，告诉innodb的磁盘读写能力，从而合理设置速度

刷脏页速度的参考因素：

- 脏页比例通过公式计算得来F1
- redo log写盘速度 计算得来F2

![img](mysql45%E8%AE%B2.assets/cc44c1d080141aa50df6a91067475374.png)

> 一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。
>
> 在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。
>
> 使用SSD时建议设置为0关闭连坐机制



### 数据库表空间

表数据可以放在共享表空间，也可每一个表单独一个文件，通过innodb_file_per_table进行设置，MYSQL 5.6 之后，默认为单独存储(on)



在删除一个数据/数据页时，只是将该处标记为可复用，而不是将空间进行回收，因此即使删除了数据，所占的空间也不会变小

而对于插入/更新的操作，由于B+树算法所涉及的叶子的分裂的问题，原本叶数据页满时，插入会分类成两个新的叶子节点，但每个叶子节点所占的空间仍为整个数据页的大小，末尾存在未分配的空间，更新操作视为先删除后插入

![img](mysql45%E8%AE%B2.assets/8083f05a4a4c0372833a6e01d5a8e6ea.png)

**重建表**

为了进行空间收缩，只能选择去进行重建表，B作为临时表，从A中按照主键顺序一条条读取数据插入到B中，再使用B替换A，此时原本未分配的空间便不在存在

- 问题：在A向B中复制数据的过程中，A不能有新的数据插入
- 解决方式：引入online DDL

**online DDL**

- 将A中的记录生成为B+树，保存到临时文件之中
- 在复制期间的对A的操作保存到一个日志文件之中，临时文件生成之后再将日志应用到临时文件之中
- alter语句启动时会获取MDL(元数据锁)写锁,但是在此拷贝数据前会退化成读锁：
  - 读锁不会阻塞CRUD，因此保证了Online
  - 读写锁之间会相互阻塞，别的线程想要DDL时获取写锁被阻塞，防止了别的线程对该DDL

**online/inplace**

- 在非online 重建表时是在server层创建了一个**临时表**，将A中的数据一条条的插入其中

- 而online DDL时，在innoDB内部创建一个**临时文件**，整个过程发生在innoDB内部，在innodb内部，表A对应的文件进行了替换而已，在server层看来，并不存在一个创建临时表的过程，始终都只有A这一张表像是一个"原地"的操作 ，称为inplace
- online的一定是inplace的，但inplace的操作并非全为online的

### count

- innoDB之中，每次使用count是都需要遍历统计数量，因此在记录多时速度会变慢
- MyISAM会统计行的总数，但也只针对一无条件的统计时才能快速获取结果，对于附带过滤条件的情况，依旧需要遍历，并且不支持事务

- show table statues返回结果很快，但获取的数据存在误差，无法替代count

**改进方案**

- 引入缓存，通过redis对其进行计数
  - 问题：
    - redis异常重启时丢失更新
    -  计数和添加数据无法保证原子性，查询可能位于二者之间
- 单独添加一张计数表：由于innodb中的事务隔离的特性，还未提交的事务对其不可见

**各类count**

- count(主键id) 遍历整张表取出id返回给server层，判断不能为空之后，按行累加
- count(字段),取出字段，判断是否为null，若不为null，则累加
- count(1)，遍历不取值，server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
- count(*) 由于 count(\*)一定不为null 对其进行了专门优化，只统计按行取值，并不将值取出

按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*),建议使用count(\*)

### order by

sort_buffer：mysql为每个线程分配一块内存用于进行排序，存储排序的字段等

**全字段排序**

将要查询的所有字段放入到sort_buffer之中，排序后将结果返回给客户端

如:

```mysql
select city,name,age from t where city='杭州' order by name limit 1000  ;
```

通过city的索引找到所有满足city等于'杭州'的行，将行上的city name age字段放入的sort_buffer之中，进行快排

> sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。
>
> number_of_tmp_files 表示的是，排序过程中使用的临时文件数，通过对多个文件进行排序，再讲多个有序文件合并成一个文件(归并？)

**rowid排序**

由于全字段排序需要将多个字段放入到sorr_buffer当中,如果要查询的字段较多开销太大，因此提出了rowid排序方式

- 只将要排序的那一个字段和主键id放入到sort_buffer当中
- 排序后再通过回表的方式获取到完整数据
- max_length_for_sort_data：如果单行的长度超过这个值，MySQL 就认为单行太大，开始使用rowid排序

**总结比较**

全字段排序和rowid排序的选择取决于内存的大小

mysql的理念是如果内存够用就尽量使用内存，减少磁盘的访问，从而提高效率

如果排序字段为索引，由于索引本身有序，则无需排序直接返回给客户端，可以看到无use fliesort，只剩use index

![image-20220615210049646](mysql45%E8%AE%B2.assets/image-20220615210049646.png)

rowid在排序时相比于全字段排序多了一次回表获取完整信息的过程，属于是以时间换空间

对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。

### 显示随机消息

在数据表中获取随机的行：order by rand() limit 

oreder by rand()大致流程：

1. 创建一张内存临时表，表的字段为要查询的字段和一个0到1的随机小数R(用于随机获取)，扫描填充内存临时表(该内存临时表无索引)
2. 初始化sort_buffer 字段为一个double类型用于存放R进行排序，另外一个为一个整形(存放位置信息)
3. 将内存临时表中的R和**位置信息**放入到sort_buffer当中
4. 在sort_buffer中对R进行排序
5. 取出前三个去临时数据表当中获取要查询的所有字段，返回给客户端

**位置信息**

表明一行数据的位置的信息

一个表在没有主键时，innoDB会自动创建一个rowid作为主键，故对于位置信息：

- 在有主键时，位置信息即为主键
- 无主键时，即为系统生成的rowid

**磁盘临时表**

在临时表过大时，使用磁盘临时表而不是内存临时表，由于获取随机数时，大多数情况只需要几个元素，故对所有元素全部进行排序便造成了浪费，因此mysql5.6之后，对于磁盘临时表的情况，采用了优先队列排序(堆排序)

如果超出了sort_buffer_size大小之后，仍会选择临时文件+归并排序的方法

### 索引未被使用

**对索引字段使用了函数**

如果对于在进行条件筛选时，对索引字段进行了函数统计，则用不上索引了，索引能够快速查询时依托于索引的搜索树结构，而如果使用了函数，对索引本身的值进行了改变，破坏了索引的有序性，因此无法在通过搜索树快速定位，只能遍历该索引

注：索引未被只用指的是索引的搜索树为生效，只能通过遍历的方式确定位置

例：

```mysql
mysql> select count(*) from tradelog where month(t_modified)=7;
```

取月份之后传入一个7无法在搜索树内判断大小

![img](mysql45%E8%AE%B2.assets/3e30d9a5e67f711f5af2e2599e800286.png)

**隐式转换类型**

如果索引字段的数据类型和条件不同时，会触发隐式条件转换，

在mysql中，字符串和数字做比较的话，是将字符串转换成数字：

- 索引为字符串，条件为整形，将索引转换为字符串，使用了函数，故不走搜索树

- 索引为整形，而判断条件为字符串，此时对判断条件进行类型转换，索引不受影响，继续走搜索树

**隐式字符编码转换**

字符编码不同时，会转换成超集的编码，如utf-8和utf8bm4之间，会转换成utf8mb4

在两个表使用的字符集不同时，如果索引字段为utf-8而条件为utf8bm4，则会触发转换，使用函数

在无法对表结构进行修改时，可以主动对条件进行转换，转换成u8和索引一致，就避免了索引进行转换的情况

### 查询等待

**查询阻塞**

- 等待MDL锁：查询时需获取读锁，MDL读写锁之间冲突
- 等flush：进行flush脏页回写时，需要关闭当前表，而如果当前表有一个很慢的事务未提交，则被阻塞
- 等行锁：`select * from t where id = 1 lock in share mode`读取时需要加行锁，需其他线程的读锁冲突，等待其他线程

**查询慢**

- 查询多行但是不走索引
- 事务A查询`select * from t where id =1`，只查询一行，但是其他线程在不断对该行进行修改，如果事务A使用的为可重复读，则需要根据undo log去不断向前计算出在事务启动时那一时刻的值，耗时巨大，相反的，如果A使用了当前读`select * from t where id = lock in share mode`读取当前值，则没有回退计算的过程，查询效率反而高

### 幻读

> 也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行

![img](mysql45%E8%AE%B2.assets/5bc506e5884d21844126d26bbe6fa68b.png)

- 在上图中，由于`for update`将其加上了排他锁，采用的为当前读，因此会将insert的新值读出，称为当前读
- 幻读只会在当前读下才会出现(无当前读由于存在事务隔离因此不会读取到最新的值)
- 幻读专指新插入的行
