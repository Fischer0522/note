# 操作系统

## 内存管理

### 抽象：地址空间

操作系统为程序提供一个物理内存的抽象，叫做**地址空间**，运行的程序感受不到这个虚拟化的过程，作为程序员，我们所操作和感知到的内存也并非真实的物理内存，因此程序的地址总是从0开始

一个地址空间包含一个程序需要的所有的内存状态，主要包括以下三个区域：

- 代码区：存储程序运行的代码

- 堆区：动态分配的内存，由用户手动管理，如malloc或者new分配的内存

- 栈区：保存函数的调用信息，分配空间给局部变量，函数返回值等，由操作系统自动管理

在地址空间中，程序代码和堆位于地址的低位，并且分配时由低位向高位进行分配，栈位于地址的高位，分配时从高位向低位分配，中间的为未分配区域，留给栈和堆进行增长

在由地址空间向物理地址的映射过程当中，主要解决的就是如何合理分配空间，使中间的未分配的区域尽可能小的占用实际物理内存

### 机制：地址转换

将指令中的虚拟地址转换到数据实际存储的地址，有点类似内存的寻址过程

**动态重定位(基于硬件)** 

实现重定位CPU需要两个寄存器，基址寄存器和限制寄存器

基址寄存器用于存放起始位置，虚拟地址的位置加上基址寄存器中的值即可得到真实的物理地址

界限寄存器确保这个地址在进程地址的空间范围内，在虚拟地址与基址寄存器求和前就进行检查，如果超过了这个界限，或者为负数时，则会引发异常

1. 创建进程时，操作系统在物理内存空间中找到一个能够容纳当前位置，并且将其标记为已用
2. 进程终止时，对当前进程所占用的内存空间进行释放，归还为空闲列表，清除当前区域的相关数据结构，比如说一个记录着当前空间大小和下一个空间位置的结构体
3. 上下文切换时，由于CPU只有一个基址寄存器和界限寄存器，因此对于不同进程之间的切换，应当保存当前寄存器中的内容到每个进程都有的结构当中，如PCB等，供上一个进程以后使用，并且将当前进程的值加载进寄存器当中。在移动地址空间时，操作系统会把新的地址空间重新更新到寄存器当中

### 分段

分段主要用于解决的就是栈和堆之间的一大块空域区域的问题。

在代码块，栈，堆这种模型下，将其分为三个段，每个段设置一对基址寄存器和界限寄存器，在进行地址映射时，分别将这三个段映射到物理地址当中

在进行映射的过程当中，由于段在虚拟地址中的起始位置不再是0，因此在进行地址映射时，应当考虑虚拟地址中段本身的偏移量，比如：

一个数据在虚拟地址中的地址为4200，而段的起始地址为4096，因此考虑段在虚拟地址中的偏移量，真正进行映射的地址(转换为段起始从0开始的地址)即为4200-4096=104，将104加上基址寄存器中的值得到的才为真正的物理地址，如果不考虑段的偏移量/起始地址，那么则与为分段无异，失去分段的意义

**段的引用**

用前几位表示段号，后几位为段内的偏移量，类似于cache的块号和块内寻址，在界限检查时，只需要将段内偏移量与界限寄存器进行比较即可

如一个14位的地址，前两位的表示段号，那么则为00-03四个段，后12位为段内偏移量

**栈的反向增长**

为了解决栈的反向增长，在段寄存器中新加一位是否进行反向增长用于区分，反向增长则为反向偏移

**共享**

部分内存可以共享给不同进程使用，但是为了防止不同进程之间的相互影响，在段寄存器当中对段加上保护位，来标识读写权限，代码段的权限位可读可执行那么则可映射到多个虚拟空间，供多个进程使用，但是每个进程又认为自己独占了这个内存

**外部碎片**

不同的段的大小不同，对物理内存空间进行划分切割，导致一些小的空间无法放下任何的段，成为外部碎片

解决方法

- 重新分配，紧凑内存，但是成本很高
- 内存分配算法，成本低，但是无法完全解决问题，总会留下碎片

### 空闲空间管理

主要解决分配过程中的外部碎片的问题

**底层机制**

堆上管理空闲空间的数据结构为空闲链表

分配空间时找到一个合适大小的空间进行分割，一部分分配，剩余的部分保持未分配的空闲状态，同时碎片也就是这么得来的

释放时一是对当前内存空间进行回收，然后对相邻的空间空间进行合并，恢复成大的空间

**实际于内存中**

当将地址分配给用户时，会同时分配一个头块，存储一定的信息，如当前段的大小和一个进行完整性检查的幻数，在对空余块进行分配时，同样会分配一个头块，其中包含着用于标识剩余空间大小的size和下一个段的位置next

分配和释放时，需要对next进行修改，指向新的下一个内存块

**算法策略**

- 最优匹配：遍历空间链表，寻找大小最合适的区域，尽可能小，但是问题时遍历性能损耗高，并且会产生小的碎片
- 最差匹配：遍历，寻找尽可能大的，会产生过量的碎片，实际表现确实是差
- 首次匹配：找到第一个就进行分配，有速度优势
- 下次匹配：相比首次匹配多维护一个指针，每次从上一次分配的结果出继续寻找空间进行分配
- 伙伴系统：分配时对空间不断进行二分，一分为二得到的两个空间称为**伙伴**直至获得一个能够分配的最小空间，释放时检查该空间的伙伴是否为空闲，如果为空闲则将二者合并，获得一个更大的空间，这个过程一直不断向上回溯合并到不能合并为止

### 分页

将空间分为大小相同的的区间，每一个区间称为一个页

与段相同，采用页号加页内偏移的方式

定义：

- 页表：实现虚拟页和实际物理页之间进行地址转换的数据结构，每个进程一个
- VPN：虚拟页面号
- PFN：物理页号
- PTE：页表格条目(页表项)，用于保存物理地址转换和任何其他有用的信息，存储在页表当中，每一对虚拟和物理地址之间的映射即每一页均需要一个页表项。PTE其中可以存储有效位、保护位、存在位、参考位（追踪页是否被访问）等信息
- TLB：地址转换旁路缓冲存储器，教材上叫做快表，类似于CPU中cache的硬件缓存
- 页目录：管理页表中的页，内部的元素成为页目录项（与页表和页表项相对应）
- PDE：页目录项，至少含有PFN和有效位

**寻址过程：**

​	已知虚拟地址，通过前几位获得VPN，通过VPN在进程中的页表中去提取适当的页表项，执行转换，得到PFN，PFN在进行左移和偏移量进行拼接得到真实的物理地址

#### TLB

**TLB算法流程**

如果在虚拟地址中提取页号，检查TLB中是否有地址映射，命中那么则直接从TLB中提取PFN，与偏移量组合得到实际的物理地址，于是可以访问内存。如果未命中则将该页从页表中提取到TLB中，避免下次访问该页的其他地址时未命中（通常系统会访问连续的地址空间）

**TLB未命中时的处理**

复杂指令集时期的计算机由硬件全权负责，未命中时硬件遍历页表，寻找正确的页表项，更新TLB

较为现代的操作系统当中通过软件处理，未命中时，硬件系统抛出一个一场，此时操作系统提升至内核模式，执行陷阱处理程序（处理TLB未命中的程序），通过特权指令修改更新TLB，从陷阱返回，此时硬件再次访问则会命中

**TLB中的内容**

VPN | PFN | 其他位

其他位包括 有效位，保护位，脏位等

**上下文切换时的TLB**

一个TLB需要针对多个进程，因此在上下文切换时，上一个进程的相关信息则没有任何意义，一共有两种处理方式：

- 上下文切换时清空TLB，但是频繁进行上下文切换时开销很高
- 跨上下文切换的TLB共享，添加地址空间标识符，用于区别不同的进程

**替换策略**

与CPU的cache相似，采用（最近最少使用）LRU和随机替换

#### 解决页表项过多的问题

正如上面所述，每一个页均需要一个页表项来进行地址映射，因此如果VPN为20位，那么则需要$2^{20}$个页表项，虽然这些页表项并不会全部有效可能为分配，但是仍存在于页表中，因此页表则会有$2^{20}$ 个项，对应的空间消耗极大。为了减少空间消耗，主要有以下几种方案：

- 更大的页
- 段页混合方法
- 多级页表

**更大的页**

使用更大的页可以减少PTE的数量，但随之每页会产生浪费，造成较大的内部碎片

**段页混合**

不在位整个进程空间提供页表，而是为每个逻辑段提供页表，如果按照代码区、堆、栈分段的话那么我们有三个页表，混合方式中我们依旧使用段中的基址寄存器和界限寄存器

在这个例子当中，段页混合之后，此时我们的虚拟地址前两位用于确定地址引用哪个段，后面剩余的分别为VPN和偏移量

分段之后，只针对段内的地址进行页表项的分配，堆和栈之间未使用的部分不再设置页表项，从而有效地节省了页表项，减少内存消耗

缺点：

分段并不像分页那么灵活，如果有一个大而稀疏的堆，我们需要对堆所在的整个段进行页表项的分配，依旧会产生较大的页表浪费

**多级页表**

基本思想：将页表分为多个页大小的单元，如果该页中的页表项全为无效，那么就完全不分配该页的页表。使用新的数据结构**页目录**来管理页表的页

页目录和页目录项对应着页表和页表项，页表和页目录用于管理具体的地址映射，页目录和页目录项用于管理页表，如果PDE有效，那么PDE指向中的页页表其中至少有一页是有效的，即该PDE指向的页中，至少有一个有效的PTE

不使用多级页表是，需要在内存找找到一个连续的空间，令页表连续的驻留在物理内存中，但是使用了多级页表之后，只需要保证能找到一段连续空间来存储页目录即可（比页表要小得多），页表的页通过页目录的指向则可以放在内存中的任意位置

缺点：

时间换空间，多页页表的查找显然要比线性页表查找复杂得多，同时TLB处理未命中时，也需要从内存中加载两次（一次页目录，一次PTE）

  TLB：如果TLB命中时则与之前线性页表一致，从TLB中获取即可，只有未命中时，才需要进行完整的多级页表查找

### 虚拟内存

#### 机制

在磁盘上开辟一块空间用于物理内存的移入和移除，通常以页大小为单元

**存在位**:表示该页是否存在于物理内存当中

**页错误：**访问该页但是该页不存在于物理内存当中，通常由操作系统软件全权负责

页错误处理流程：

- 硬件在地址转换中的工作

  - TLB命中，直接从从TLB中获取
  - TLB未命中，但是该页存在且有效，那么直接从PTE中获取对应的PFN,换入TLB中，再次重试则TLB命中
  - TLB未命中，且该页不在物理内存当中，执行页错误处理程序，将该页换到物理内存当中去，按照在物理内存中的处理方法继续执行
  - TLB未命中，且该页无效，硬件捕获这个非法访问，操作系统调用陷阱程序，可能会结束这个非法进程

- 操作系统在页错误时所作的工作：

  首先操作系统为将要换入的页找到一个物理空间，如果没有则执行交换算法踢出一些页，获得物理帧之后重新请求从交换空间读取页，操作系统更新页表重试指令，此时TLB会未命中，交换到TLB当中去，再次重试则TLB命中

#### 策略

如果将物理内存视为cache，硬盘视为内存，那么则可以按照cache命中的那一套思路去思考

因此，我们目前最应当关系的为命中率和平均访问时间

**最优替换策略**

替换内存中在最远的将来才被访问的页，可以达到缓存未命中率最低

但是未来的访问无法得知，因此无法为操作系统实现最优策略，只能用于评估算法时作为其他算法的参考

**FIFO**

先进先出，无法确定页的重要性，导致命中率很低，甚至比随机替换的效果还差

**随机**

不过多解释

**LRU**

最少最近使用，由于访问的**近期性(时间局部性)**，利用历史数据，替换最近最少使用的页面

相比于FIFO和随机，能够更好的保持热门页，取得较好的效果

为了实现LRU，需要对每次内存引用进行记录，再删除时还需遍历所有页，寻找近期最少使用的页来进行替换，导致了巨大的时间开销，因此引出的近似LRU算法

**近似LRU**

周期性的清楚使用位，然后通过使用位的0和1来区分近期是否被使用过，来判断使用哪个页

比较有代表性的为时钟算法：

所有页放在一个循环列表当中，开始时指针指向一个页，如果该页为1那么则为近期使用过，不进行替换，往后遍历直至寻找到第一个不是1的页，将其进行替换，遍历过的位置均设置为0

**考虑脏页**

脏页代表从进行过修改的页，如果此时再写回硬盘中，那么则会带来额外的硬盘开销，因此替换时不应当有限考虑脏页，通过增加一个修改位，达到区分脏页的目的

